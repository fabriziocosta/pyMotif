{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Optimization for different noise levels in artificial datasets </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from smod_wrapper import SMoDWrapper\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eden.util import configure_logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "configure_logging(logger,verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def random_string(length,alphabet_list):\n",
    "    rand_str = ''.join(random.choice(alphabet_list) for i in range(length))\n",
    "    return rand_str\n",
    "\n",
    "def perturb(seed,alphabet_list,p=0.5):\n",
    "    seq=''\n",
    "    for c in seed:\n",
    "        if random.random() < p: c = random.choice(alphabet_list)\n",
    "        seq += c\n",
    "    return seq\n",
    "\n",
    "def make_artificial_dataset(alphabet='ACGT', motives=None, motif_length=6, \n",
    "                            sequence_length=100, n_sequences=1000, n_motives=2, p=0.2,\n",
    "                           random_state=1):\n",
    "    random.seed(random_state)\n",
    "\n",
    "    alphabet_list=[c for c in alphabet]\n",
    "    \n",
    "    if motives is None:\n",
    "        motives=[]\n",
    "        for i in range(n_motives):\n",
    "            motives.append(random_string(motif_length,alphabet_list))\n",
    "    else:\n",
    "        motif_length = len(motives[0])\n",
    "        n_motives = len(motives)\n",
    "    \n",
    "    sequence_length = sequence_length / len(motives)\n",
    "    flanking_length = (sequence_length - motif_length ) / 2\n",
    "    n_seq_per_motif = n_sequences\n",
    "\n",
    "    counter=0\n",
    "    seqs=[]\n",
    "    for i in range(n_seq_per_motif):\n",
    "        total_seq = ''\n",
    "        total_binary_seq=''\n",
    "        for j in range(n_motives):\n",
    "            left_flanking = random_string(flanking_length,alphabet_list)\n",
    "            right_flanking = random_string(flanking_length,alphabet_list)\n",
    "            noisy_motif = perturb(motives[j],alphabet_list,p)\n",
    "            seq = left_flanking + noisy_motif + right_flanking\n",
    "            total_seq += seq\n",
    "        seqs.append(('ID%d'%counter,total_seq))\n",
    "        counter += 1\n",
    "    binary_skeleton = '0' * flanking_length + '1' * motif_length + '0' * flanking_length\n",
    "    binary_seq = binary_skeleton * n_motives\n",
    "    return motives, seqs, binary_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_seqs(seqs, n_motives, tool):\n",
    "    scores = []\n",
    "    if tool is None:\n",
    "        return scores\n",
    "    \n",
    "    for j in range(len(seqs)):\n",
    "        seq_scr = []\n",
    "        iters = tool.nmotifs\n",
    "        for k in range(iters):\n",
    "            scr=tool.score(motif_num=k+1, seq=seqs[j][1])\n",
    "            seq_scr.append(scr)\n",
    "\n",
    "        # taking average over all motives for a sequence\n",
    "        if len(seq_scr) > 1:\n",
    "            x = np.array(seq_scr[0])\n",
    "            for l in range(1, iters):\n",
    "                x = np.vstack((x, seq_scr[l]))\n",
    "            seq_scr = list(np.mean(x, axis=0))\n",
    "            scores.append(seq_scr)\n",
    "        elif len(seq_scr) == 1:\n",
    "            scores.append(np.array(seq_scr[0]))\n",
    "        else:\n",
    "            raise ValueError(\"no sequence score\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(sequence_length=200,\n",
    "                n_sequences=200,\n",
    "                motif_length=10,\n",
    "                n_motives=2, \n",
    "                p=0.2,\n",
    "                random_state=1):\n",
    "    \n",
    "    motives, pos_seqs, binary_seq = make_artificial_dataset(alphabet='ACGT',\n",
    "                                                            sequence_length=sequence_length,\n",
    "                                                            n_sequences=n_sequences,\n",
    "                                                            motif_length=motif_length,\n",
    "                                                            n_motives=n_motives,\n",
    "                                                            p=p, \n",
    "                                                            random_state=random_state)\n",
    "\n",
    "    from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
    "    neg_seqs = seq_to_seq(pos_seqs, modifier=shuffle_modifier, times=2, order=2)\n",
    "    neg_seqs = list(neg_seqs)\n",
    "\n",
    "    block_size=n_sequences/8\n",
    "\n",
    "    pos_size = len(pos_seqs)\n",
    "    train_pos_seqs = pos_seqs[:pos_size/2]\n",
    "    test_pos_seqs = pos_seqs[pos_size/2:]\n",
    "\n",
    "    neg_size = len(neg_seqs)\n",
    "    train_neg_seqs = neg_seqs[:neg_size/2]\n",
    "    test_neg_seqs = neg_seqs[neg_size/2:]\n",
    "\n",
    "    true_score = [float(int(i)) for i in binary_seq]\n",
    "    return (block_size, train_pos_seqs, train_neg_seqs, test_pos_seqs, n_motives, true_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_on_datasets(n_sets = 5, param_setting=None, p=0.2, max_roc=0.5, std_roc=0.01):\n",
    "    dataset_score = []\n",
    "    seeds = [i * 2000 for i in range(1, n_sets + 1)]\n",
    "    for k in range(n_sets):\n",
    "        # Generate data set\n",
    "        seed = seeds[k]\n",
    "        data = get_dataset(sequence_length=40,\n",
    "                           n_sequences=50,\n",
    "                           motif_length=10,\n",
    "                           n_motives=2,\n",
    "                           p=p,\n",
    "                           random_state=seed)\n",
    "        block_size = data[0]\n",
    "        train_pos_seqs = data[1]\n",
    "        train_neg_seqs = data[2]\n",
    "        test_pos_seqs = data[3]\n",
    "        n_motives = data[4]\n",
    "        true_score = data[5]\n",
    "\n",
    "        smod = SMoDWrapper(alphabet = 'dna',\n",
    "                           scoring_criteria = 'pwm',\n",
    "\n",
    "                           complexity = 5,\n",
    "                           n_clusters = 10,\n",
    "                           min_subarray_size = 8,\n",
    "                           max_subarray_size = 12,\n",
    "                           clusterer = KMeans(),\n",
    "                           pos_block_size = block_size,\n",
    "                           neg_block_size = block_size,\n",
    "                           # sample_size = 300,\n",
    "                           p_value = param_setting['p_value'],\n",
    "                           similarity_th = param_setting['similarity_th'],\n",
    "                           min_score = param_setting['min_score'],\n",
    "                           min_freq = param_setting['min_freq'],\n",
    "                           min_cluster_size = param_setting['min_cluster_size'],\n",
    "                           regex_th = param_setting['regex_th'],\n",
    "                           freq_th = param_setting['freq_th'],\n",
    "                           std_th = param_setting['std_th']) \n",
    "\n",
    "        \n",
    "\n",
    "        try:\n",
    "            smod.fit(train_pos_seqs, train_neg_seqs)\n",
    "            scores = score_seqs(seqs = test_pos_seqs,\n",
    "                                n_motives = n_motives,\n",
    "                                tool = smod)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        mean_score = np.mean(scores, axis=0)\n",
    "        roc_score = roc_auc_score(true_score, mean_score)\n",
    "\n",
    "\n",
    "        # if a parameter setting performs poorly, don't test on other datasets\n",
    "        # z-score = (x - mu)/sigma\n",
    "        # if ((roc_score - max_roc)/std_roc) > 2:\n",
    "        if roc_score < 0.6:\n",
    "            break\n",
    "\n",
    "        dataset_score.append(roc_score)\n",
    "    return dataset_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_validity(key, value, noise):\n",
    "    if key == 'min_score':    # atleast greater than (motif_length)/2\n",
    "        if value >= 5:\n",
    "            return True, int(round(value))\n",
    "    elif key == 'min_cluster_size':\n",
    "        if value >= 3:\n",
    "            return True, int(round(value))\n",
    "    elif key == 'min_freq':    # atmost (1 - noise_level)\n",
    "        if value > 0 and value <= (1 - noise):\n",
    "            return True, value\n",
    "    elif key == 'p_value':\n",
    "        if value <= 1.0 and value >= 0.0:\n",
    "            return True, value\n",
    "    elif key == 'similarity_th':\n",
    "        if value <= 1.0 and value >= 0.8:\n",
    "            return True, value\n",
    "    elif key == 'regex_th':\n",
    "        if value > 0 and value <= 0.3:\n",
    "            return True, value\n",
    "    elif key == 'freq_th':\n",
    "        if value <= 1.0 and value > 0:\n",
    "            return True, value\n",
    "    elif key == 'std_th':\n",
    "        if value <= 1.0 and value > 0:\n",
    "            return True, value\n",
    "    else:\n",
    "        raise ValueError('Invalid key: ', key)\n",
    "    return False, value\n",
    "\n",
    "def random_setting(parameters=None, best_config=None, noise=None):\n",
    "    parameter_setting = {}\n",
    "    MAX_ITER = 1000\n",
    "    if not parameters['min_score']:    # use best_configuration of last run as initial setting\n",
    "        for key in parameters.keys():\n",
    "            parameters[key].append(best_config[key])\n",
    "            parameter_setting[key] = best_config[key]\n",
    "    else:\n",
    "        for key in parameters.keys():\n",
    "            success = False\n",
    "            n_iter = 0\n",
    "            mu = np.mean(parameters[key])\n",
    "            sigma = np.mean(parameters[key])\n",
    "            if sigma == 0:\n",
    "                sigma == 0.1\n",
    "            while not success:\n",
    "                if n_iter == MAX_ITER:    # if max_iterations exceeded, return mean as value\n",
    "                    value = mu\n",
    "                    if key in ['min_score', 'min_cluster_size']:\n",
    "                        value = int(round(value))\n",
    "                    break\n",
    "                value = np.random.normal(mu, 2 * sigma)\n",
    "                n_iter += 1\n",
    "                success, value = check_validity(key, value, noise)\n",
    "            parameter_setting[key] = value\n",
    "    return parameter_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:26:42 Starting experiment...\n",
      "\n",
      "07:26:48 Better Configuration found at perturbation prob =  0.1\n",
      "ROC:  0.7\n",
      "Parameter Configuration:  {'min_freq': 0.1, 'min_score': 6, 'p_value': 0.1, 'min_cluster_size': 3, 'std_th': 0.2, 'regex_th': 0.3, 'similarity_th': 0.8, 'freq_th': 0.05}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print datetime.datetime.fromtimestamp(time.time()).strftime('%H:%M:%S'),\n",
    "print \"Starting experiment...\\n\"\n",
    "\n",
    "best_config = {'min_score':6, # atleast motif_length/2\n",
    "               'min_freq':0.1, # can not be more than (1- noise level)\n",
    "               'min_cluster_size':3, # atleast 3\n",
    "               'p_value':0.1, # atleast 0.1\n",
    "               'similarity_th':0.8, # 0.8 \n",
    "               'regex_th':0.3, # max 0.3 \n",
    "               'freq_th':0.05, # 0.05 \n",
    "               'std_th':0.2} # 0.2\n",
    "\n",
    "# Final results\n",
    "param = [0.1, 0.2, 0.3]#, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results_dic = {}\n",
    "\n",
    "reps = 30 #0    # different settings to be tried\n",
    "\n",
    "for i in param:\n",
    "    parameters = {'min_freq': [],\n",
    "                  'min_cluster_size': [],\n",
    "                  'p_value': [],\n",
    "                  'similarity_th': [],\n",
    "                  'min_score': [],\n",
    "                  'regex_th': [],\n",
    "                  'freq_th': [],\n",
    "                  'std_th': []}\n",
    "    max_roc = 0.5\n",
    "    std_roc = 0.01\n",
    "    #parameters = generate_dist(parameters, best_config)\n",
    "    for j in range(reps):\n",
    "        param_setting = random_setting(parameters, best_config, i)    # Randomize Parameter setting\n",
    "        n_sets = 5    # Different data sets\n",
    "        dataset_score = test_on_datasets(n_sets=n_sets, \n",
    "                                         param_setting=param_setting, \n",
    "                                         p=i, \n",
    "                                         max_roc=max_roc,\n",
    "                                         std_roc=std_roc)\n",
    "        mean_roc = np.mean(dataset_score)\n",
    "        std = np.std(dataset_score)\n",
    "\n",
    "        if mean_roc > max_roc:\n",
    "            max_roc = mean_roc\n",
    "            std_roc = std\n",
    "            print datetime.datetime.fromtimestamp(time.time()).strftime('%H:%M:%S'),\n",
    "            print \"Better Configuration found at perturbation prob = \", i\n",
    "            print \"ROC: \", mean_roc\n",
    "            print \"Parameter Configuration: \", param_setting\n",
    "            print\n",
    "            best_config = param_setting\n",
    "            param_setting[\"ROC\"] = mean_roc\n",
    "            results_dic[i] = param_setting\n",
    "            \n",
    "print datetime.datetime.fromtimestamp(time.time()).strftime('%H:%M:%S'),\n",
    "print \" Finished experiment...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
