{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eden.util import configure_logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "configure_logging(logger,verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def random_string(length,alphabet_list):\n",
    "    rand_str = ''.join(random.choice(alphabet_list) for i in range(length))\n",
    "    return rand_str\n",
    "\n",
    "def perturb(seed,alphabet_list,p=0.5):\n",
    "    seq=''\n",
    "    for c in seed:\n",
    "        if random.random() < p: c = random.choice(alphabet_list)\n",
    "        seq += c\n",
    "    return seq\n",
    "\n",
    "def make_artificial_dataset(alphabet='ACGT', motives=None, motif_length=6, \n",
    "                            sequence_length=100, n_sequences=1000, n_motives=2, p=0.2,\n",
    "                           random_state=1):\n",
    "    random.seed(random_state)\n",
    "    alphabet_list=[c for c in alphabet]\n",
    "    \n",
    "    if motives is None:\n",
    "        motives=[]\n",
    "        for i in range(n_motives):\n",
    "            motives.append(random_string(motif_length,alphabet_list))\n",
    "    else:\n",
    "        motif_length = len(motives[0])\n",
    "        n_motives = len(motives)\n",
    "    \n",
    "    sequence_length = sequence_length / len(motives)\n",
    "    flanking_length = (sequence_length - motif_length ) / 2\n",
    "    n_seq_per_motif = n_sequences\n",
    "\n",
    "    counter=0\n",
    "    seqs=[]\n",
    "    for i in range(n_seq_per_motif):\n",
    "        total_seq = ''\n",
    "        total_binary_seq=''\n",
    "        for j in range(n_motives):\n",
    "            left_flanking = random_string(flanking_length,alphabet_list)\n",
    "            right_flanking = random_string(flanking_length,alphabet_list)\n",
    "            noisy_motif = perturb(motives[j],alphabet_list,p)\n",
    "            seq = left_flanking + noisy_motif + right_flanking\n",
    "            total_seq += seq\n",
    "        seqs.append(('ID%d'%counter,total_seq))\n",
    "        counter += 1\n",
    "    binary_skeleton = '0' * flanking_length + '1' * motif_length + '0' * flanking_length\n",
    "    binary_seq = binary_skeleton * n_motives\n",
    "    return motives, seqs, binary_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from smod_wrapper import SMoDWrapper\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motives=None\n",
    "motif_length=4\n",
    "n_motives=1\n",
    "sequence_length=8\n",
    "n_sequences=10\n",
    "perturbation_prob=0.05\n",
    "\n",
    "complexity=5\n",
    "min_score=4\n",
    "min_freq=0.25\n",
    "min_cluster_size=5\n",
    "n_clusters=15\n",
    "min_subarray_size=3\n",
    "max_subarray_size=5\n",
    "similarity_threshold=.9\n",
    "freq_threshold=0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motives, pos_seqs, binary_seq = make_artificial_dataset(alphabet='ACGT',\n",
    "                                                        motives=motives,\n",
    "                                                        sequence_length=sequence_length,\n",
    "                                                        n_sequences=n_sequences,\n",
    "                                                        motif_length=motif_length,\n",
    "                                                        n_motives=n_motives,\n",
    "                                                        p=perturbation_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
    "neg_seqs = seq_to_seq(pos_seqs, modifier=shuffle_modifier, times=1, order=2)\n",
    "neg_seqs = list(neg_seqs)\n",
    "\n",
    "block_size=n_sequences/8\n",
    "\n",
    "pos_size = len(pos_seqs)\n",
    "train_pos_seqs = pos_seqs[:pos_size/2]\n",
    "test_pos_seqs = pos_seqs[pos_size/2:]\n",
    "\n",
    "neg_size = len(neg_seqs)\n",
    "train_neg_seqs = neg_seqs[:neg_size/2]\n",
    "test_neg_seqs = neg_seqs[neg_size/2:]\n",
    "\n",
    "true_score = [float(int(i)) for i in binary_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup 0.04 secs\n",
      "Fitting\n",
      "0 (1, 32769) (0.02 secs) (delta: 0.02)\n",
      "1 (1, 32769) (0.02 secs) (delta: 0.00)\n",
      "2 (1, 32769) (0.02 secs) (delta: 0.00)\n",
      "3 (1, 32769) (0.02 secs) (delta: 0.00)\n",
      "4 (1, 32769) (0.02 secs) (delta: 0.00)\n",
      "5 (1, 32769) (0.03 secs) (delta: 0.00)\n",
      "6 (1, 32769) (0.03 secs) (delta: 0.00)\n",
      "7 (1, 32769) (0.03 secs) (delta: 0.00)\n",
      "8 (1, 32769) (0.03 secs) (delta: 0.00)\n",
      "9 (1, 32769) (0.03 secs) (delta: 0.00)\n",
      "Setup 0.06 secs\n",
      "Annotating\n",
      "0 (0.00 secs) (delta: 0.00)\n",
      "1 (0.02 secs) (delta: 0.02)\n",
      "2 (0.02 secs) (delta: 0.00)\n",
      "3 (0.02 secs) (delta: 0.00)\n",
      "4 (0.03 secs) (delta: 0.00)\n",
      "5 (0.03 secs) (delta: 0.00)\n",
      "6 (0.03 secs) (delta: 0.00)\n",
      "7 (0.03 secs) (delta: 0.00)\n",
      "8 (0.03 secs) (delta: 0.00)\n",
      "9 (0.03 secs) (delta: 0.00)\n",
      "Warning: reverting to default values\n",
      "ECDF fit on 0 values\n",
      "Optimal params: a:-4.00  b:1.00\n",
      "Setup 0.07 secs\n",
      "Annotating\n",
      "0 (0.00 secs) (delta: 0.00)\n",
      "1 (0.01 secs) (delta: 0.00)\n",
      "2 (0.01 secs) (delta: 0.00)\n",
      "3 (0.01 secs) (delta: 0.00)\n",
      "4 (0.02 secs) (delta: 0.01)\n",
      "5 (0.02 secs) (delta: 0.00)\n",
      "6 (0.02 secs) (delta: 0.00)\n",
      "7 (0.02 secs) (delta: 0.00)\n",
      "8 (0.02 secs) (delta: 0.00)\n",
      "9 (0.02 secs) (delta: 0.00)\n",
      "Working on: 5 fragments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-26:\n",
      "Process PoolWorker-30:\n",
      "Process PoolWorker-31:\n",
      "Process PoolWorker-29:\n",
      "Process PoolWorker-28:\n",
      "Process PoolWorker-32:\n",
      "Process PoolWorker-25:\n",
      "Process PoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    racquire()\n",
      "    racquire()\n",
      "    racquire()\n",
      "    racquire()\n",
      "    racquire()\n",
      "    racquire()\n",
      "    return recv()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e5a7fea103fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                    \u001b[0msimilarity_th\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                    freq_th = freq_threshold)\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0msmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_seqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/zr/Dropbox/HiWi/pyMotif/smod_wrapper.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, seqs, neg_seqs)\u001b[0m\n\u001b[0;32m    118\u001b[0m                                           \u001b[0msample_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                                           \u001b[0mfreq_th\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq_th\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                                           std_th=self.std_th)\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnmotifs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmotives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zr/eden/EDeN/eden/sequence_motif_decomposer.pyc\u001b[0m in \u001b[0;36mselect_motives\u001b[1;34m(self, seqs, p_value, similarity_th, min_score, min_freq, min_cluster_size, regex_th, sample_size, freq_th, std_th)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                        std_th=None):\n\u001b[0;32m   1234\u001b[0m         \u001b[1;34m\"\"\"select_motives.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[0morig_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_clusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m         motives = self.compute_motives(\n\u001b[0;32m   1237\u001b[0m             \u001b[0morig_clusters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zr/eden/EDeN/eden/sequence_motif_decomposer.pyc\u001b[0m in \u001b[0;36mcompute_clusters\u001b[1;34m(self, seqs, p_value)\u001b[0m\n\u001b[0;32m    964\u001b[0m                 \u001b[0mvectorizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m                 \u001b[0mpos_block_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_block_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m                 n_jobs=self.n_jobs)\n\u001b[0m\u001b[0;32m    967\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Clustering'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'working on %d instances'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zr/eden/EDeN/eden/sequence_motif_decomposer.pyc\u001b[0m in \u001b[0;36mmultiprocess_vectorize\u001b[1;34m(iterable, vectorizer, pos_block_size, n_jobs)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserial_pre_process\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         args=(seqs, vectorizer))\n\u001b[1;32m--> 369\u001b[1;33m         for seqs in chunks(iterable, pos_block_size)]\n\u001b[0m\u001b[0;32m    370\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Setup %.2f secs'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Vectorizing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zr/eden/EDeN/eden/__init__.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(pool, fun, args, callback)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mworkaround\u001b[0m \u001b[0mto\u001b[0m \u001b[0menable\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0mof\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \"\"\"\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_dill_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zr/anaconda2/envs/hiwi/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, args, kwds, callback)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mApplyResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_taskqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zr/anaconda2/envs/hiwi/lib/python2.7/Queue.pyc\u001b[0m in \u001b[0;36mput\u001b[1;34m(self, item, block, timeout)\u001b[0m\n\u001b[0;32m    135\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_put\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munfinished_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "smod = SMoDWrapper(alphabet='dna',\n",
    "                   scoring_criteria = 'pwm',\n",
    "                   complexity = complexity,\n",
    "                   n_clusters = n_clusters,\n",
    "                   min_subarray_size = min_subarray_size,\n",
    "                   max_subarray_size = max_subarray_size,\n",
    "                   pos_block_size = block_size,\n",
    "                   neg_block_size = block_size,\n",
    "                   clusterer = KMeans(),\n",
    "                   min_score = min_score,\n",
    "                   min_freq = min_freq,\n",
    "                   min_cluster_size = min_cluster_size,\n",
    "                   similarity_th = similarity_threshold,\n",
    "                   freq_th = freq_threshold)\n",
    "smod.fit(pos_seqs, neg_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_seqs(seqs, n_motives, tool):\n",
    "    scores = []\n",
    "    for j in range(len(seqs)):\n",
    "        seq_scr = []\n",
    "        iters = tool.nmotifs\n",
    "        for k in range(iters):\n",
    "            scr=tool.score(motif_num=k+1, seq=seqs[j][1])\n",
    "            seq_scr.append(scr)\n",
    "\n",
    "        # taking average over all motives for a sequence\n",
    "\n",
    "        x = np.array(seq_scr[0])\n",
    "        for l in range(1, iters):\n",
    "            x = np.vstack((x, seq_scr[l]))\n",
    "        seq_scr = list(np.mean(x, axis=0))\n",
    "        scores.append(seq_scr)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = score_seqs(seqs=test_pos_seqs,\n",
    "                    n_motives=n_motives,\n",
    "                    tool=smod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in scores: \n",
    "    print i\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_scores = []\n",
    "for score in scores:\n",
    "    roc_scores.append(roc_auc_score(true_score, score))\n",
    "avg_roc = np.average(roc_scores)\n",
    "std_roc = np.std(roc_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54533593749999998"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pylab as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(scores[0])+1), scores[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(1,len(scores[0])+1), scores[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1a90160150>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a902bb110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1,2,3,4,5],[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0020490403660952121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0003662109375, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.00080296131179190158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.00025380049979175338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 5.3416353082679358e-07, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 3.0874236974991391e-07, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0012044419676878523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.005583610995418575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0015228029987505204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
